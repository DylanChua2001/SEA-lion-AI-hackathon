services:
  api:
    build:
      context: .
    ports:
      - "8001:8001"
    environment:
      - PYTHONUNBUFFERED=1
      - USE_MOCK_LLM=false
      - VLLM_BASE_URL=http://vllm:8000/v1
      - MODEL_ID=aisingapore/Llama-SEA-LION-v3.5-8B-R
      # Override if needed:
      # - MONGODB_URI=mongodb://host.docker.internal:27017/lingolah_sea_lion_llm
    depends_on:
      - vllm

  vllm:
    image: vllm/vllm-openai:latest
    command: ["python", "-m", "vllm.entrypoints.openai.api_server", "--model", "aisingapore/Llama-SEA-LION-v3.5-8B-R", "--host", "0.0.0.0", "--port", "8000"]
    ports:
      - "8002:8000"
    # GPU is recommended for SEA-LION. Uncomment if you have NVIDIA GPU support enabled in Docker Desktop.
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - capabilities: ["gpu"]

